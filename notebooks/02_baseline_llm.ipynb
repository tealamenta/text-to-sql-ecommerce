{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Baseline LLM : Zero-Shot Text-to-SQL\n",
    "\n",
    "**Objectif** : Établir une baseline en testant le LLM sans optimisation\n",
    "\n",
    "**Approche** : Zero-shot = on donne juste le schéma + la question\n",
    "\n",
    "**Métriques** :\n",
    "- **Execution Accuracy (EX)** : Le SQL s'exécute et donne le bon résultat\n",
    "- **Exact Match (EM)** : Le SQL généré = SQL attendu (après normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database: ../data/database/ecommerce.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "DB_PATH = DATA_DIR / 'database' / 'ecommerce.db'\n",
    "\n",
    "# Vérifier que la DB existe\n",
    "assert DB_PATH.exists(), f'DB not found: {DB_PATH}'\n",
    "print(f'✓ Database: {DB_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHÉMA DDL\n",
      "============================================================\n",
      "CREATE TABLE customers (\n",
      "  customer_id TEXT,\n",
      "  customer_city TEXT,\n",
      "  customer_state TEXT\n",
      ");\n",
      "\n",
      "CREATE TABLE products (\n",
      "  product_id TEXT,\n",
      "  product_category TEXT,\n",
      "  product_weight_g REAL,\n",
      "  product_length_cm REAL,\n",
      "  product_height_cm REAL,\n",
      "  product_width_cm REAL\n",
      ");\n",
      "\n",
      "CREATE TABLE orders (\n",
      "  order_id TEXT,\n",
      "  customer_id TEXT,\n",
      "  order_status TEXT,\n",
      "  order_purchase_timestamp TEXT,\n",
      "  order_delivered_timestamp TEXT\n",
      ");\n",
      "\n",
      "CREATE TABLE order_items (\n",
      "  order_id TEXT,\n",
      "  order_item_id INTEGER,\n",
      "  product_id TEXT,\n",
      "  price REAL,\n",
      "  freight_value REAL\n",
      ");\n",
      "\n",
      "CREATE TABLE payments (\n",
      "  order_id TEXT,\n",
      "  payment_sequential INTEGER,\n",
      "  payment_type TEXT,\n",
      "  payment_installments INTEGER,\n",
      "  payment_value REAL\n",
      ");\n",
      "\n",
      "CREATE TABLE reviews (\n",
      "  review_id TEXT,\n",
      "  order_id TEXT,\n",
      "  review_score INTEGER,\n",
      "  review_comment_title TEXT,\n",
      "  review_comment_message TEXT\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "# Charger le schéma\n",
    "with open(DATA_DIR / 'database' / 'schema.sql', 'r') as f:\n",
    "    SCHEMA = f.read()\n",
    "\n",
    "print('SCHÉMA DDL')\n",
    "print('='*60)\n",
    "print(SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 12 questions\n",
      "  [simple] Combien de commandes au total ?\n",
      "  [simple] Combien de clients différents ?\n",
      "  [simple] Combien de commandes livrées ?\n"
     ]
    }
   ],
   "source": [
    "# Charger le test set\n",
    "with open(DATA_DIR / 'results' / 'test_questions.json', 'r') as f:\n",
    "    TEST_QUESTIONS = json.load(f)\n",
    "\n",
    "print(f'Test set: {len(TEST_QUESTIONS)} questions')\n",
    "for q in TEST_QUESTIONS[:3]:\n",
    "    print(f'  [{q[\"difficulty\"]}] {q[\"question\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connecté à la base\n"
     ]
    }
   ],
   "source": [
    "# Connexion DB\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "print('✓ Connecté à la base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Client LLM (Ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Test: In SQL, we don't have a direct command to say \"hello\", but you can create a table and insert a row w\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "OLLAMA_URL = 'http://localhost:11434/api/generate'\n",
    "MODEL = 'mistral'\n",
    "\n",
    "def call_llm(prompt: str, temperature: float = 0.0) -> str:\n",
    "    \"\"\"Appeler le LLM via Ollama.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            OLLAMA_URL,\n",
    "            json={\n",
    "                'model': MODEL,\n",
    "                'prompt': prompt,\n",
    "                'stream': False,\n",
    "                'options': {\n",
    "                    'temperature': temperature,\n",
    "                    'num_predict': 300\n",
    "                }\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "        return response.json().get('response', '').strip()\n",
    "    except Exception as e:\n",
    "        return f'ERROR: {e}'\n",
    "\n",
    "# Test\n",
    "test_response = call_llm('Say hello in SQL style')\n",
    "print(f'LLM Test: {test_response[:100]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt Zero-Shot (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL:\n",
      "SELECT COUNT(DISTINCT order_id) FROM orders;\n"
     ]
    }
   ],
   "source": [
    "# Prompt template baseline (minimal)\n",
    "BASELINE_PROMPT = '''Given the following SQL schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Write a SQL query to answer this question:\n",
    "{question}\n",
    "\n",
    "Return ONLY the SQL query, nothing else.'''\n",
    "\n",
    "def generate_sql_baseline(question: str) -> str:\n",
    "    \"\"\"Générer SQL avec prompt baseline.\"\"\"\n",
    "    prompt = BASELINE_PROMPT.format(schema=SCHEMA, question=question)\n",
    "    response = call_llm(prompt)\n",
    "    \n",
    "    # Extraire le SQL (enlever markdown si présent)\n",
    "    sql = response.strip()\n",
    "    \n",
    "    # Nettoyer les balises markdown\n",
    "    if '```sql' in sql:\n",
    "        sql = sql.split('```sql')[1].split('```')[0].strip()\n",
    "    elif '```' in sql:\n",
    "        sql = sql.split('```')[1].split('```')[0].strip()\n",
    "    \n",
    "    return sql\n",
    "\n",
    "# Test\n",
    "test_sql = generate_sql_baseline('Combien de commandes au total ?')\n",
    "print(f'Generated SQL:\\n{test_sql}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Métriques d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fonctions de métriques définies\n"
     ]
    }
   ],
   "source": [
    "def normalize_sql(sql: str) -> str:\n",
    "    \"\"\"Normaliser SQL pour comparaison.\"\"\"\n",
    "    # Lowercase\n",
    "    sql = sql.lower()\n",
    "    # Remove extra whitespace\n",
    "    sql = ' '.join(sql.split())\n",
    "    # Remove trailing semicolon\n",
    "    sql = sql.rstrip(';')\n",
    "    return sql\n",
    "\n",
    "def execute_sql(sql: str, conn) -> tuple:\n",
    "    \"\"\"Exécuter SQL et retourner (success, result).\"\"\"\n",
    "    try:\n",
    "        result = pd.read_sql(sql, conn)\n",
    "        return True, result\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "def compare_results(result1: pd.DataFrame, result2: pd.DataFrame) -> bool:\n",
    "    \"\"\"Comparer deux résultats de requêtes.\"\"\"\n",
    "    try:\n",
    "        # Même shape\n",
    "        if result1.shape != result2.shape:\n",
    "            return False\n",
    "        \n",
    "        # Comparer les valeurs (tri par première colonne)\n",
    "        r1 = result1.sort_values(by=result1.columns[0]).reset_index(drop=True)\n",
    "        r2 = result2.sort_values(by=result2.columns[0]).reset_index(drop=True)\n",
    "        \n",
    "        # Comparer\n",
    "        return r1.equals(r2) or r1.values.tolist() == r2.values.tolist()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def exact_match(sql1: str, sql2: str) -> bool:\n",
    "    \"\"\"Vérifier si deux SQL sont identiques (après normalisation).\"\"\"\n",
    "    return normalize_sql(sql1) == normalize_sql(sql2)\n",
    "\n",
    "print('✓ Fonctions de métriques définies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Évaluation Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fonction d'évaluation définie\n"
     ]
    }
   ],
   "source": [
    "def evaluate_question(question_data: dict, conn) -> dict:\n",
    "    \"\"\"Évaluer une question.\"\"\"\n",
    "    question = question_data['question']\n",
    "    expected_sql = question_data['sql']\n",
    "    difficulty = question_data['difficulty']\n",
    "    \n",
    "    # Générer SQL\n",
    "    generated_sql = generate_sql_baseline(question)\n",
    "    \n",
    "    # Exécuter SQL généré\n",
    "    gen_success, gen_result = execute_sql(generated_sql, conn)\n",
    "    \n",
    "    # Exécuter SQL attendu\n",
    "    exp_success, exp_result = execute_sql(expected_sql, conn)\n",
    "    \n",
    "    # Métriques\n",
    "    em = exact_match(generated_sql, expected_sql)\n",
    "    ex = False\n",
    "    if gen_success and exp_success:\n",
    "        ex = compare_results(gen_result, exp_result)\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'difficulty': difficulty,\n",
    "        'expected_sql': expected_sql,\n",
    "        'generated_sql': generated_sql,\n",
    "        'execution_success': gen_success,\n",
    "        'exact_match': em,\n",
    "        'execution_accuracy': ex,\n",
    "        'error': None if gen_success else gen_result\n",
    "    }\n",
    "\n",
    "print('✓ Fonction d\\'évaluation définie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÉVALUATION BASELINE\n",
      "============================================================\n",
      "Model: mistral\n",
      "Prompt: Zero-shot (schéma + question)\n",
      "Questions: 12\n",
      "============================================================\n",
      "[1/12] [simple] ✓ run | ✓ EX | ✗ EM\n",
      "   Q: Combien de commandes au total ?...\n",
      "\n",
      "[2/12] [simple] ✓ run | ✗ EX | ✗ EM\n",
      "   Q: Combien de clients différents ?...\n",
      "\n",
      "[3/12] [simple] ✓ run | ✗ EX | ✗ EM\n",
      "   Q: Combien de commandes livrées ?...\n",
      "\n",
      "[4/12] [simple] ✓ run | ✓ EX | ✗ EM\n",
      "   Q: Quel est le nombre de produits dans le catalogue ?...\n",
      "\n",
      "[5/12] [medium] ✗ run | ✗ EX | ✗ EM\n",
      "   Q: Quelles sont les 5 villes avec le plus de clients ...\n",
      "   Error: Execution failed on sql 'SELECT customer_city, COUNT(customer_id) as number_of_c...\n",
      "\n",
      "[6/12] [medium] ✓ run | ✓ EX | ✗ EM\n",
      "   Q: Quel est le revenue total par catégorie de produit...\n",
      "\n",
      "[7/12] [medium] ✓ run | ✗ EX | ✗ EM\n",
      "   Q: Quelle est la note moyenne par catégorie de produi...\n",
      "\n",
      "[8/12] [medium] ✓ run | ✗ EX | ✗ EM\n",
      "   Q: Combien de commandes par méthode de paiement ?...\n",
      "\n",
      "[9/12] [complex] ✓ run | ✗ EX | ✗ EM\n",
      "   Q: Quels clients ont passé plus de 2 commandes ?...\n",
      "\n",
      "[10/12] [complex] ✗ run | ✗ EX | ✗ EM\n",
      "   Q: Quel est le panier moyen par ville ?...\n",
      "   Error: Execution failed on sql 'SELECT customer_city, AVG(total_price) as average_cart\n",
      "...\n",
      "\n",
      "[11/12] [complex] ✓ run | ✗ EX | ✗ EM\n",
      "   Q: Quels produits ont une note moyenne inférieure à 3...\n",
      "\n",
      "[12/12] [complex] ✗ run | ✗ EX | ✗ EM\n",
      "   Q: Quel est le délai moyen de livraison par état ?...\n",
      "   Error: Execution failed on sql 'SELECT customer_state, AVG(DATEDIFF('day', order_purcha...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluer toutes les questions\n",
    "print('ÉVALUATION BASELINE')\n",
    "print('='*60)\n",
    "print(f'Model: {MODEL}')\n",
    "print(f'Prompt: Zero-shot (schéma + question)')\n",
    "print(f'Questions: {len(TEST_QUESTIONS)}')\n",
    "print('='*60)\n",
    "\n",
    "results = []\n",
    "for i, q in enumerate(TEST_QUESTIONS):\n",
    "    result = evaluate_question(q, conn)\n",
    "    results.append(result)\n",
    "    \n",
    "    # Status\n",
    "    status_ex = '✓' if result['execution_accuracy'] else '✗'\n",
    "    status_em = '✓' if result['exact_match'] else '✗'\n",
    "    status_run = '✓' if result['execution_success'] else '✗'\n",
    "    \n",
    "    print(f'[{i+1}/{len(TEST_QUESTIONS)}] [{result[\"difficulty\"]}] {status_run} run | {status_ex} EX | {status_em} EM')\n",
    "    print(f'   Q: {result[\"question\"][:50]}...')\n",
    "    if not result['execution_success']:\n",
    "        print(f'   Error: {result[\"error\"][:80]}...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RÉSULTATS BASELINE\n",
      "============================================================\n",
      "Execution Success: 9/12 (75.0%)\n",
      "Execution Accuracy (EX): 3/12 (25.0%)\n",
      "Exact Match (EM): 0/12 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Calculer les métriques globales\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Métriques globales\n",
    "total = len(df_results)\n",
    "exec_success = df_results['execution_success'].sum()\n",
    "ex_correct = df_results['execution_accuracy'].sum()\n",
    "em_correct = df_results['exact_match'].sum()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('RÉSULTATS BASELINE')\n",
    "print('='*60)\n",
    "print(f'Execution Success: {exec_success}/{total} ({exec_success/total:.1%})')\n",
    "print(f'Execution Accuracy (EX): {ex_correct}/{total} ({ex_correct/total:.1%})')\n",
    "print(f'Exact Match (EM): {em_correct}/{total} ({em_correct/total:.1%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Par difficulté:\n",
      "----------------------------------------\n",
      "SIMPLE   | EX: 2/4 (50%) | EM: 0/4 (0%)\n",
      "MEDIUM   | EX: 1/4 (25%) | EM: 0/4 (0%)\n",
      "COMPLEX  | EX: 0/4 (0%) | EM: 0/4 (0%)\n"
     ]
    }
   ],
   "source": [
    "# Métriques par difficulté\n",
    "print('\\nPar difficulté:')\n",
    "print('-'*40)\n",
    "\n",
    "for diff in ['simple', 'medium', 'complex']:\n",
    "    subset = df_results[df_results['difficulty'] == diff]\n",
    "    n = len(subset)\n",
    "    if n > 0:\n",
    "        ex = subset['execution_accuracy'].sum()\n",
    "        em = subset['exact_match'].sum()\n",
    "        print(f'{diff.upper():8} | EX: {ex}/{n} ({ex/n:.0%}) | EM: {em}/{n} ({em/n:.0%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreurs d'exécution: 3\n",
      "\n",
      "============================================================\n",
      "Question: Quelles sont les 5 villes avec le plus de clients ?\n",
      "Difficulty: medium\n",
      "\n",
      "Generated SQL:\n",
      "SELECT customer_city, COUNT(customer_id) as number_of_customers\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "GROUP BY customer_city\n",
      "ORDER BY number_of_customers DESC\n",
      "LIMIT 5;\n",
      "\n",
      "Error: Execution failed on sql 'SELECT customer_city, COUNT(customer_id) as number_of_customers\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "GROUP BY customer_city\n",
      "ORDER BY number_of_customers DESC\n",
      "LIMIT 5;': ambiguous column name: customer_id\n",
      "\n",
      "============================================================\n",
      "Question: Quel est le panier moyen par ville ?\n",
      "Difficulty: complex\n",
      "\n",
      "Generated SQL:\n",
      "SELECT customer_city, AVG(total_price) as average_cart\n",
      "FROM (\n",
      "  SELECT o.customer_id, SUM(oi.price + oi.freight_value) as total_price\n",
      "  FROM orders o\n",
      "  JOIN order_items oi ON o.order_id = oi.order_id\n",
      "  GROUP BY o.customer_id, o.customer_city\n",
      ") as carts\n",
      "GROUP BY customer_city;\n",
      "\n",
      "Error: Execution failed on sql 'SELECT customer_city, AVG(total_price) as average_cart\n",
      "FROM (\n",
      "  SELECT o.customer_id, SUM(oi.price + oi.freight_value) as total_price\n",
      "  FROM orders o\n",
      "  JOIN order_items oi ON o.order_id = oi.order_id\n",
      "  GROUP BY o.customer_id, o.customer_city\n",
      ") as carts\n",
      "GROUP BY customer_city;': no such column: o.customer_city\n",
      "\n",
      "============================================================\n",
      "Question: Quel est le délai moyen de livraison par état ?\n",
      "Difficulty: complex\n",
      "\n",
      "Generated SQL:\n",
      "SELECT customer_state, AVG(DATEDIFF('day', order_purchase_timestamp, order_delivered_timestamp)) as average_delivery_delay\n",
      "FROM orders\n",
      "JOIN customers ON orders.customer_id = customers.customer_id\n",
      "GROUP BY customer_state;\n",
      "\n",
      "Error: Execution failed on sql 'SELECT customer_state, AVG(DATEDIFF('day', order_purchase_timestamp, order_delivered_timestamp)) as average_delivery_delay\n",
      "FROM orders\n",
      "JOIN customers ON orders.customer_id = customers.customer_id\n",
      "GROUP BY customer_state;': no such function: DATEDIFF\n"
     ]
    }
   ],
   "source": [
    "# Voir les erreurs\n",
    "errors = df_results[~df_results['execution_success']]\n",
    "print(f'Erreurs d\\'exécution: {len(errors)}')\n",
    "\n",
    "for _, row in errors.iterrows():\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Question: {row[\"question\"]}')\n",
    "    print(f'Difficulty: {row[\"difficulty\"]}')\n",
    "    print(f'\\nGenerated SQL:')\n",
    "    print(row['generated_sql'])\n",
    "    print(f'\\nError: {row[\"error\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats incorrects: 6\n",
      "\n",
      "============================================================\n",
      "Question: Combien de clients différents ?\n",
      "\n",
      "Expected SQL:\n",
      "SELECT COUNT(DISTINCT customer_id) as total FROM customers\n",
      "\n",
      "Generated SQL:\n",
      "SELECT DISTINCT customer_id FROM customers;\n",
      "\n",
      "============================================================\n",
      "Question: Combien de commandes livrées ?\n",
      "\n",
      "Expected SQL:\n",
      "SELECT COUNT(*) as total FROM orders WHERE order_status = 'delivered'\n",
      "\n",
      "Generated SQL:\n",
      "SELECT COUNT(DISTINCT orders.order_id) FROM orders INNER JOIN order_items ON orders.order_id = order_items.order_id INNER JOIN payments ON orders.order_id = payments.order_id WHERE orders.order_delivered_timestamp IS NOT NULL;\n",
      "\n",
      "============================================================\n",
      "Question: Quelle est la note moyenne par catégorie de produit ?\n",
      "\n",
      "Expected SQL:\n",
      "SELECT p.product_category, ROUND(AVG(r.review_score), 2) as avg_score\n",
      "                  FROM reviews r\n",
      "                  JOIN orders o ON r.order_id = o.order_id\n",
      "                  JOIN order_items oi ON o.order_id = oi.order_id\n",
      "                  JOIN products p ON oi.product_id = p.product_id\n",
      "                  GROUP BY p.product_category\n",
      "                  ORDER BY avg_score DESC\n",
      "\n",
      "Generated SQL:\n",
      "SELECT product_category, AVG(reviews.review_score) as average_score\n",
      "FROM reviews\n",
      "JOIN order_items ON reviews.order_id = order_items.order_id\n",
      "JOIN products ON order_items.product_id = products.product_id\n",
      "GROUP BY product_category;\n",
      "\n",
      "============================================================\n",
      "Question: Combien de commandes par méthode de paiement ?\n",
      "\n",
      "Expected SQL:\n",
      "SELECT payment_type, COUNT(DISTINCT order_id) as num_orders\n",
      "                  FROM payments\n",
      "                  GROUP BY payment_type\n",
      "                  ORDER BY num_orders DESC\n",
      "\n",
      "Generated SQL:\n",
      "SELECT COUNT(DISTINCT order_id) as number_of_orders, payment_type\n",
      "FROM payments\n",
      "GROUP BY payment_type;\n",
      "\n",
      "============================================================\n",
      "Question: Quels clients ont passé plus de 2 commandes ?\n",
      "\n",
      "Expected SQL:\n",
      "SELECT c.customer_id, c.customer_city, COUNT(o.order_id) as num_orders\n",
      "                  FROM customers c\n",
      "                  JOIN orders o ON c.customer_id = o.customer_id\n",
      "                  GROUP BY c.customer_id, c.customer_city\n",
      "                  HAVING COUNT(o.order_id) > 2\n",
      "                  ORDER BY num_orders DESC\n",
      "\n",
      "Generated SQL:\n",
      "SELECT customer_id\n",
      "FROM orders\n",
      "GROUP BY customer_id\n",
      "HAVING COUNT(DISTINCT order_id) > 2;\n",
      "\n",
      "============================================================\n",
      "Question: Quels produits ont une note moyenne inférieure à 3 ?\n",
      "\n",
      "Expected SQL:\n",
      "SELECT p.product_id, p.product_category, ROUND(AVG(r.review_score), 2) as avg_score\n",
      "                  FROM products p\n",
      "                  JOIN order_items oi ON p.product_id = oi.product_id\n",
      "                  JOIN reviews r ON oi.order_id = r.order_id\n",
      "                  GROUP BY p.product_id, p.product_category\n",
      "                  HAVING AVG(r.review_score) < 3\n",
      "                  ORDER BY avg_score ASC\n",
      "\n",
      "Generated SQL:\n",
      "SELECT product_id\n",
      "FROM order_items\n",
      "JOIN reviews ON order_items.order_id = reviews.order_id\n",
      "GROUP BY product_id\n",
      "HAVING AVG(reviews.review_score) < 3;\n"
     ]
    }
   ],
   "source": [
    "# Voir les EX incorrects (SQL valide mais mauvais résultat)\n",
    "wrong_results = df_results[df_results['execution_success'] & ~df_results['execution_accuracy']]\n",
    "print(f'Résultats incorrects: {len(wrong_results)}')\n",
    "\n",
    "for _, row in wrong_results.iterrows():\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Question: {row[\"question\"]}')\n",
    "    print(f'\\nExpected SQL:')\n",
    "    print(row['expected_sql'])\n",
    "    print(f'\\nGenerated SQL:')\n",
    "    print(row['generated_sql'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sauvegarder les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Résultats sauvegardés: ../data/results/baseline_results.json\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder\n",
    "baseline_results = {\n",
    "    'model': MODEL,\n",
    "    'prompt_type': 'zero-shot',\n",
    "    'total_questions': total,\n",
    "    'metrics': {\n",
    "        'execution_success': exec_success / total,\n",
    "        'execution_accuracy': ex_correct / total,\n",
    "        'exact_match': em_correct / total\n",
    "    },\n",
    "    'by_difficulty': {},\n",
    "    'details': results\n",
    "}\n",
    "\n",
    "for diff in ['simple', 'medium', 'complex']:\n",
    "    subset = df_results[df_results['difficulty'] == diff]\n",
    "    n = len(subset)\n",
    "    if n > 0:\n",
    "        baseline_results['by_difficulty'][diff] = {\n",
    "            'total': n,\n",
    "            'execution_accuracy': subset['execution_accuracy'].sum() / n,\n",
    "            'exact_match': subset['exact_match'].sum() / n\n",
    "        }\n",
    "\n",
    "with open(DATA_DIR / 'results' / 'baseline_results.json', 'w') as f:\n",
    "    json.dump(baseline_results, f, indent=2, default=str)\n",
    "\n",
    "print(f'✓ Résultats sauvegardés: {DATA_DIR / \"results\" / \"baseline_results.json\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "### Baseline établie :\n",
    "- **Prompt** : Zero-shot (schéma + question)\n",
    "- **Execution Accuracy** : X%\n",
    "- **Exact Match** : X%\n",
    "\n",
    "### Observations :\n",
    "- Les requêtes simples fonctionnent bien\n",
    "- Les JOINs complexes posent problème\n",
    "- Erreurs fréquentes : noms de colonnes, syntaxe SQLite\n",
    "\n",
    "### Prochaine étape :\n",
    "**Notebook 03** : Ajouter RAG pour le schema linking (trouver les bonnes tables/colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print('Connexion fermée.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
